#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆCAVEæ•°æ®é›†ç”Ÿæˆæµ‹è¯•
"""

import os
import h5py
import numpy as np

def test_simplified_dataset():
    """æµ‹è¯•ç®€åŒ–ç‰ˆæ•°æ®é›†ç”Ÿæˆ"""
    print("ğŸ§ª æµ‹è¯•ç®€åŒ–ç‰ˆCAVEæ•°æ®é›†")
    print("="*50)
    
    # å‡è®¾çš„æ•°æ®æ–‡ä»¶è·¯å¾„
    train_file = "/data2/users/yujieliang/dataset/CAVE/CAVE_train_patches_stride32_size128.h5"
    test_file = "/data2/users/yujieliang/dataset/CAVE/CAVE_test_fullsize.h5"
    
    print("ğŸ“‚ æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®é›†æ–‡ä»¶...")
    
    # æ£€æŸ¥è®­ç»ƒé›†
    if os.path.exists(train_file):
        print(f"âœ… è®­ç»ƒé›†å­˜åœ¨: {train_file}")
        with h5py.File(train_file, 'r') as f:
            print("   è®­ç»ƒé›†å†…å®¹:")
            for key in f.keys():
                print(f"     {key}: {f[key].shape}, dtype={f[key].dtype}")
            
            print("   è®­ç»ƒé›†å±æ€§:")
            for attr_name, attr_value in f.attrs.items():
                print(f"     {attr_name}: {attr_value}")
                
            # æ£€æŸ¥æ•°æ®èŒƒå›´
            gt_data = f['GT'][:]
            print(f"\n   æ•°æ®èŒƒå›´æ£€æŸ¥:")
            print(f"     GT: [{gt_data.min():.4f}, {gt_data.max():.4f}]")
            
            if 'LRHSI_4' in f:
                lrhsi_data = f['LRHSI_4'][:]
                print(f"     LRHSI_4: [{lrhsi_data.min():.4f}, {lrhsi_data.max():.4f}]")
            
            if 'lms_4' in f:
                lms_data = f['lms_4'][:]
                print(f"     LMS_4: [{lms_data.min():.4f}, {lms_data.max():.4f}]")
    else:
        print(f"âŒ è®­ç»ƒé›†ä¸å­˜åœ¨: {train_file}")
    
    # æ£€æŸ¥æµ‹è¯•é›†
    if os.path.exists(test_file):
        print(f"\nâœ… æµ‹è¯•é›†å­˜åœ¨: {test_file}")
        with h5py.File(test_file, 'r') as f:
            print("   æµ‹è¯•é›†å†…å®¹:")
            for key in f.keys():
                if key != 'image_names':
                    print(f"     {key}: {f[key].shape}, dtype={f[key].dtype}")
                else:
                    names = [name.decode('utf-8') for name in f[key][:]]
                    print(f"     {key}: {names}")
            
            print("   æµ‹è¯•é›†å±æ€§:")
            for attr_name, attr_value in f.attrs.items():
                print(f"     {attr_name}: {attr_value}")
    else:
        print(f"âŒ æµ‹è¯•é›†ä¸å­˜åœ¨: {test_file}")
    
    print("\n" + "="*50)
    print("âœ… ç®€åŒ–ç‰ˆæ•°æ®é›†æµ‹è¯•å®Œæˆ!")
    
    print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹ (æ— éœ€å½’ä¸€åŒ–):")
    print("""
import h5py
import torch
from torch.utils.data import Dataset

class CAVEDataset(Dataset):
    def __init__(self, h5_file):
        self.h5_file = h5_file
        with h5py.File(h5_file, 'r') as f:
            self.length = f['GT'].shape[0]
    
    def __getitem__(self, idx):
        with h5py.File(self.h5_file, 'r') as f:
            gt = torch.from_numpy(f['GT'][idx]).float()
            lrhsi = torch.from_numpy(f['LRHSI_4'][idx]).float()
            lms = torch.from_numpy(f['lms_4'][idx]).float()
            
        return {'gt': gt, 'lrhsi': lrhsi, 'lms': lms}
    
    def __len__(self):
        return self.length

# ä½¿ç”¨ç¤ºä¾‹
dataset = CAVEDataset('CAVE_train_patches.h5')
dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)

for batch in dataloader:
    gt = batch['gt']      # (B, 31, 128, 128)
    lrhsi = batch['lrhsi'] # (B, 31, 32, 32) for factor=4
    lms = batch['lms']     # (B, 31, 128, 128)
    break
""")

if __name__ == '__main__':
    test_simplified_dataset()
