#!/usr/bin/env python3
"""
æ¼”ç¤ºCAVEæ•°æ®é›†å½’ä¸€åŒ–ä½¿ç”¨æ–¹æ³•
"""

import h5py
import numpy as np

def demo_normalization():
    """æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æœ€å¤§å€¼å½’ä¸€åŒ–"""
    print("ğŸ“Š CAVEæ•°æ®é›†å½’ä¸€åŒ–ç¤ºä¾‹")
    print("="*50)
    
    # å‡è®¾çš„æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ›¿æ¢ä¸ºå®é™…è·¯å¾„ï¼‰
    train_file = "/data2/users/yujieliang/dataset/CAVE/CAVE_train_patches_stride32_size128.h5"
    test_file = "/data2/users/yujieliang/dataset/CAVE/CAVE_test_fullsize.h5"
    
    print("ğŸ“‚ åŠ è½½è®­ç»ƒé›†æ•°æ®...")
    try:
        with h5py.File(train_file, 'r') as f:
            print("å¯ç”¨çš„æ•°æ®é›†:")
            for key in f.keys():
                print(f"   {key}: {f[key].shape}")
            
            print("\nå¯ç”¨çš„å½’ä¸€åŒ–å‚æ•°:")
            for attr_name in f.attrs.keys():
                if attr_name.endswith('_max') or attr_name.endswith('_min'):
                    print(f"   {attr_name}: {f.attrs[attr_name]:.4f}")
            
            # åŠ è½½ä¸€äº›æ•°æ®è¿›è¡Œæ¼”ç¤º
            gt_data = f['GT'][:5]  # åªå–å‰5ä¸ªpatches
            lrhsi_4_data = f['LRHSI_4'][:5]
            lms_4_data = f['lms_4'][:5]
            
            # è·å–å½’ä¸€åŒ–å‚æ•°
            gt_max = f.attrs['gt_max']
            lrhsi_4_max = f.attrs['LRHSI_4_max']
            lms_4_max = f.attrs['lms_4_max']
            
            print(f"\nğŸ”¢ åŸå§‹æ•°æ®èŒƒå›´:")
            print(f"   GT: [{gt_data.min():.4f}, {gt_data.max():.4f}]")
            print(f"   LRHSI_4: [{lrhsi_4_data.min():.4f}, {lrhsi_4_data.max():.4f}]")
            print(f"   LMS_4: [{lms_4_data.min():.4f}, {lms_4_data.max():.4f}]")
            
            # è¿›è¡Œå½’ä¸€åŒ–
            gt_normalized = gt_data / gt_max
            lrhsi_4_normalized = lrhsi_4_data / lrhsi_4_max
            lms_4_normalized = lms_4_data / lms_4_max
            
            print(f"\nâœ¨ å½’ä¸€åŒ–åæ•°æ®èŒƒå›´:")
            print(f"   GT: [{gt_normalized.min():.4f}, {gt_normalized.max():.4f}]")
            print(f"   LRHSI_4: [{lrhsi_4_normalized.min():.4f}, {lrhsi_4_normalized.max():.4f}]")
            print(f"   LMS_4: [{lms_4_normalized.min():.4f}, {lms_4_normalized.max():.4f}]")
            
            print(f"\nğŸ“‹ å½’ä¸€åŒ–å…¬å¼:")
            print(f"   normalized_data = original_data / max_value")
            print(f"   æ¢å¤å…¬å¼: original_data = normalized_data * max_value")
            
    except FileNotFoundError:
        print(f"âŒ è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨: {train_file}")
        print("è¯·å…ˆè¿è¡Œ generate_cave_dataset.py ç”Ÿæˆæ•°æ®é›†")
    
    print("\n" + "="*50)
    print("âœ… å½’ä¸€åŒ–æ¼”ç¤ºå®Œæˆ!")
    
    print("\nğŸ’¡ åœ¨PyTorchè®­ç»ƒä¸­çš„ä½¿ç”¨:")
    print("""
import torch
from torch.utils.data import Dataset

class CAVEDataset(Dataset):
    def __init__(self, h5_file):
        self.h5_file = h5_file
        with h5py.File(h5_file, 'r') as f:
            self.gt_max = f.attrs['gt_max']
            self.lrhsi_4_max = f.attrs['LRHSI_4_max']
            self.lms_4_max = f.attrs['lms_4_max']
            self.length = f['GT'].shape[0]
    
    def __getitem__(self, idx):
        with h5py.File(self.h5_file, 'r') as f:
            gt = torch.from_numpy(f['GT'][idx]).float() / self.gt_max
            lrhsi = torch.from_numpy(f['LRHSI_4'][idx]).float() / self.lrhsi_4_max
            lms = torch.from_numpy(f['lms_4'][idx]).float() / self.lms_4_max
            
        return {'gt': gt, 'lrhsi': lrhsi, 'lms': lms}
    
    def __len__(self):
        return self.length

# ä½¿ç”¨ç¤ºä¾‹
dataset = CAVEDataset('CAVE_train_patches.h5')
dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)
""")

if __name__ == '__main__':
    demo_normalization()
