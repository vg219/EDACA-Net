#!/usr/bin/env python3
"""
PaviaCenteræ•°æ®é›†ç”Ÿæˆè„šæœ¬
ç”Ÿæˆæ ‡å‡†æ ¼å¼çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ŒåŒ…å«GT, HRMSI, LRHSI_X, lms_Xæ•°æ®

æ•°æ®æµç¨‹:
1. GT (Ground Truth) - åŸå§‹102é€šé“é«˜å…‰è°±æ•°æ®
2. HRMSI - 3é€šé“RGBæ•°æ®
3. LRHSI_X - GTé€šè¿‡Interp23TapæŠ—æ··å ä¸‹é‡‡æ ·Xå€å¾—åˆ°çš„ä½åˆ†è¾¨ç‡é«˜å…‰è°±æ•°æ®
4. lms_X - LRHSI_Xé€šè¿‡åŒçº¿æ€§æ’å€¼ä¸Šé‡‡æ ·å›åŸå°ºå¯¸å¾—åˆ°çš„ä½åˆ†è¾¨ç‡å¤šå…‰è°±æ•°æ®

è®­ç»ƒé›†ï¼š1096x1096å›¾åƒï¼Œé‡å è£åˆ‡128x128 patches
æµ‹è¯•é›†ï¼šå·¦ä¸Šè§’1024x1024åŒºåŸŸï¼Œä¸é‡å è£åˆ‡4ä¸ª512x512 patches

ä½œè€…: Assistant
æ—¥æœŸ: 2025-08-11
"""

import os
import sys
import numpy as np
import h5py
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.nn.functional as F
import argparse
import math
from pathlib import Path

# Botswanaé…ç½®å‚æ•°
PAVIA_CONFIG = {
    'pavia_file': '/data2/users/yujieliang/exps/Efficient-MIF-back-master-6-feat/data/Botswana/Botswana_RGB.h5',
    'output_dir': '/data2/users/yujieliang/exps/Efficient-MIF-back-master-6-feat/data/Botswana/datasets',
    
    # è®­ç»ƒé›†å‚æ•°
    'train_patch_size': 128,
    'train_stride': 16,  # é‡å è£åˆ‡
    
    # æµ‹è¯•é›†å‚æ•°
    'test_crop_width': 256,   # å·¦ä¸Šè§’è£åˆ‡å®½åº¦
    'test_crop_height': 1280,   # å·¦ä¸Šè§’è£åˆ‡é«˜åº¦
    'test_patch_size': 256,    # æµ‹è¯•patchå°ºå¯¸ (1024/2=512, 1Ã—2=2ä¸ªpatches)
    
    'downsample_factors': [4, 8, 16, 32],
    'compression_level': 9,
    
    # Botswanaç‰¹å®šå‚æ•°
    'original_size': (1476, 256),
    'num_bands': 145,  # PaviaUæœ‰103ä¸ªå…‰è°±é€šé“
}

class Interp23Tap(nn.Module):
    """
    PyTorch implementation of the interp23tap MATLAB function.
    (å¤ç”¨Harvardä»£ç ä¸­çš„å®ç°)
    """

    def __init__(self, ratio: int, pad_mode: str = "replicate"):
        super().__init__()

        if not (ratio > 0 and (ratio & (ratio - 1) == 0)):
            raise ValueError("Error: Only resize factors power of 2 are supported.")
        self.ratio = ratio
        self.num_upsamples = int(math.log2(ratio))
        self.pad_mode = pad_mode

        # Define the 23-tap filter coefficients (CDF23 from MATLAB code)
        cdf23_coeffs = 2.0 * np.array([
            0.5, 0.305334091185, 0.0, -0.072698593239, 0.0, 0.021809577942,
            0.0, -0.005192756653, 0.0, 0.000807762146, 0.0, -0.000060081482,
        ])
        # Make symmetric
        base_coeffs = np.concatenate([np.flip(cdf23_coeffs[1:]), cdf23_coeffs])
        base_coeffs_t = torch.tensor(base_coeffs, dtype=torch.float32)

        # Reshape kernel for 2D convolution (separable filter)
        kernel_h = base_coeffs_t.view(1, 1, -1, 1)  # Shape (1, 1, 23, 1)
        kernel_w = base_coeffs_t.view(1, 1, 1, -1)  # Shape (1, 1, 1, 23)

        # Register kernels as buffers
        self.register_buffer("kernel_h", kernel_h)
        self.register_buffer("kernel_w", kernel_w)

        # Calculate padding size (kernel_size=23)
        self.padding = (base_coeffs_t.shape[0] - 1) // 2  # Should be 11

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass for interpolation."""
        if self.ratio == 1:
            return x

        current_img = x
        bs, c, h_curr, w_curr = current_img.shape

        for k in range(self.num_upsamples):
            h_curr *= 2
            w_curr *= 2

            # Upsample by inserting zeros
            upsampled = torch.zeros(
                bs, c, h_curr, w_curr, device=x.device, dtype=x.dtype
            )

            # Place original pixels according to MATLAB logic
            if k == 0:
                upsampled[..., 1::2, 1::2] = current_img
            else:
                upsampled[..., ::2, ::2] = current_img

            # Apply separable convolution with circular padding
            # Pad for horizontal filter (width)
            padded_w = F.pad(
                upsampled, (self.padding, self.padding, 0, 0), mode=self.pad_mode
            )
            # Apply horizontal filter
            kernel_w_grouped = self.kernel_w.repeat(c, 1, 1, 1)
            filtered_w = F.conv2d(padded_w, kernel_w_grouped, groups=c)

            # Pad for vertical filter (height)
            padded_h = F.pad(
                filtered_w, (0, 0, self.padding, self.padding), mode="circular"
            )
            # Apply vertical filter
            kernel_h_grouped = self.kernel_h.repeat(c, 1, 1, 1)
            filtered_h = F.conv2d(padded_h, kernel_h_grouped, groups=c)

            current_img = filtered_h  # Update image for next iteration

        return current_img

def anti_aliasing_downsample(image_tensor, factor, device):
    """ä½¿ç”¨Interp23Tapè¿›è¡ŒæŠ—æ··å ä¸‹é‡‡æ ·"""
    if factor == 1:
        return image_tensor
    
    # æ·»åŠ batchç»´åº¦
    img_batch = image_tensor.unsqueeze(0).to(device)  # (1, C, H, W)
    
    # ä½¿ç”¨Interp23Tapçš„æ»¤æ³¢æ ¸è¿›è¡ŒæŠ—æ··å é¢„å¤„ç†
    cdf23_coeffs = 2.0 * np.array([
        0.5, 0.305334091185, 0.0, -0.072698593239, 0.0, 0.021809577942,
        0.0, -0.005192756653, 0.0, 0.000807762146, 0.0, -0.000060081482,
    ])
    base_coeffs = np.concatenate([np.flip(cdf23_coeffs[1:]), cdf23_coeffs])
    base_coeffs_t = torch.tensor(base_coeffs, dtype=torch.float32, device=device)
    
    # åˆ›å»ºåˆ†ç¦»æ»¤æ³¢æ ¸
    kernel_h = base_coeffs_t.view(1, 1, -1, 1)  # å‚ç›´æ»¤æ³¢æ ¸
    kernel_w = base_coeffs_t.view(1, 1, 1, -1)  # æ°´å¹³æ»¤æ³¢æ ¸
    padding = (len(base_coeffs) - 1) // 2
    
    # åº”ç”¨æŠ—æ··å æ»¤æ³¢
    bs, c, h, w = img_batch.shape
    
    # æ°´å¹³æ»¤æ³¢
    padded_w = F.pad(img_batch, (padding, padding, 0, 0), mode='replicate')
    kernel_w_grouped = kernel_w.repeat(c, 1, 1, 1)
    filtered_w = F.conv2d(padded_w, kernel_w_grouped, groups=c)
    
    # å‚ç›´æ»¤æ³¢
    padded_h = F.pad(filtered_w, (0, 0, padding, padding), mode='replicate')
    kernel_h_grouped = kernel_h.repeat(c, 1, 1, 1)
    filtered_h = F.conv2d(padded_h, kernel_h_grouped, groups=c)
    
    # ä¸‹é‡‡æ ·ï¼ˆå­é‡‡æ ·ï¼‰
    downsampled = filtered_h[:, :, ::factor, ::factor]
    
    return downsampled.squeeze(0)  # ç§»é™¤batchç»´åº¦

class PaviaCenterDatasetGenerator:
    """PaviaCenteræ•°æ®é›†ç”Ÿæˆå™¨"""
    
    def __init__(self, config=None, gpu_ids=[0]):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.config = config or PAVIA_CONFIG.copy()
        
        # è®¾ç½®GPUæ”¯æŒ
        self.gpu_ids = gpu_ids if torch.cuda.is_available() else []
        if self.gpu_ids:
            self.device = torch.device(f'cuda:{gpu_ids[0]}')
            print(f"ä½¿ç”¨GPU: {gpu_ids}, ä¸»è®¾å¤‡: {self.device}")
        else:
            self.device = torch.device('cpu')
            print("ä½¿ç”¨CPU")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.config['output_dir'], exist_ok=True)
        
    def load_pavia_data(self):
        """åŠ è½½PaviaUæ•°æ®"""
        print("ğŸ“‚ åŠ è½½PaviaUæ•°æ®...")
        
        pavia_file = self.config['pavia_file']
        if not os.path.exists(pavia_file):
            raise FileNotFoundError(f"PaviaUæ–‡ä»¶ä¸å­˜åœ¨: {pavia_file}")
        
        with h5py.File(pavia_file, 'r') as f:
            # æ£€æŸ¥æ–‡ä»¶å†…å®¹
            print(f"   æ–‡ä»¶ä¸­çš„æ•°æ®é›†: {list(f.keys())}")
            
            # åŠ è½½æ•°æ® - PaviaCenteråªæœ‰ä¸€å¼ å›¾åƒ
            self.gt_data = f['gt'][:]        # (C, H, W) - 102é€šé“
            self.hrmsi_data = f['HRMSI'][:]  # (3, H, W) - RGB
            
            # æ£€æŸ¥æ•°æ®å½¢çŠ¶
            print(f"   GTæ•°æ®: {self.gt_data.shape}")
            print(f"   HRMSIæ•°æ®: {self.hrmsi_data.shape}")
            
            # ç¡®ä¿æ˜¯å•å¼ å›¾åƒæ ¼å¼
            if len(self.gt_data.shape) != 3:
                raise ValueError(f"æœŸæœ›GTæ•°æ®ä¸º(C,H,W)æ ¼å¼ï¼Œå®é™…ä¸º{self.gt_data.shape}")
            
            # éªŒè¯å°ºå¯¸
            expected_size = self.config['original_size']
            actual_size = self.gt_data.shape[-2:]
            if actual_size != expected_size:
                print(f"   è­¦å‘Š: å›¾åƒå°ºå¯¸ {actual_size} ä¸æœŸæœ›å°ºå¯¸ {expected_size} ä¸åŒ¹é…")
                self.config['original_size'] = actual_size
            
            # éªŒè¯é€šé“æ•°
            expected_bands = self.config['num_bands']
            actual_bands = self.gt_data.shape[0]
            if actual_bands != expected_bands:
                print(f"   è­¦å‘Š: å…‰è°±é€šé“æ•° {actual_bands} ä¸æœŸæœ›é€šé“æ•° {expected_bands} ä¸åŒ¹é…")
                self.config['num_bands'] = actual_bands
            
            print(f"   æ•°å€¼èŒƒå›´: GT[{self.gt_data.min():.6f}, {self.gt_data.max():.6f}]")
            print(f"   å›¾åƒå°ºå¯¸: {actual_size} (H x W)")
            print(f"   å…‰è°±é€šé“: {actual_bands}")
            
            # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
            if 'dataset_name' in f.attrs:
                self.dataset_name = f.attrs['dataset_name']
            else:
                self.dataset_name = 'PaviaCenter'
            
            print(f"   æ•°æ®é›†åç§°: {self.dataset_name}")
        
    def crop_patches_overlapping(self, image, patch_size, stride):
        """ä½¿ç”¨é‡å æ»‘åŠ¨çª—å£è£å‰ªpatches"""
        if len(image.shape) == 3:  # (C, H, W)
            c, h, w = image.shape
        else:  # (H, W)
            h, w = image.shape
        
        patches = []
        positions = []
        
        for y in range(0, h - patch_size + 1, stride):
            for x in range(0, w - patch_size + 1, stride):
                if len(image.shape) == 3:  # (C, H, W)
                    patch = image[:, y:y+patch_size, x:x+patch_size]
                else:  # (H, W)
                    patch = image[y:y+patch_size, x:x+patch_size]
                patches.append(patch)
                positions.append((y, x))
        
        return patches, positions
    
    def crop_test_patches_non_overlapping(self, image, crop_width, crop_height, patch_size):
        """
        ä»å·¦ä¸Šè§’crop_widthÃ—crop_heightåŒºåŸŸä¸é‡å è£å‰ªpatch_sizeçš„patches
        # å¯¹äº1024Ã—512è£å‰ª512Ã—512ï¼Œå¾—åˆ°1Ã—2=2ä¸ªpatches
        """
        # å…ˆè£å‰ªå·¦ä¸Šè§’åŒºåŸŸ
        if len(image.shape) == 3:  # (C, H, W)
            cropped = image[:, :crop_height, :crop_width]
        else:  # (H, W)
            cropped = image[:crop_height, :crop_width]
        
        patches = []
        positions = []
        
        # è®¡ç®—patchesçš„è¡Œåˆ—æ•°
        patches_per_row = crop_height // patch_size   # 512 // 512 = 1
        patches_per_col = crop_width // patch_size    # 1024 // 512 = 2
        
        for row in range(patches_per_row):
            for col in range(patches_per_col):
                y = row * patch_size
                x = col * patch_size
                
                if len(image.shape) == 3:  # (C, H, W)
                    patch = cropped[:, y:y+patch_size, x:x+patch_size]
                else:  # (H, W)
                    patch = cropped[y:y+patch_size, x:x+patch_size]
                
                patches.append(patch)
                positions.append((y, x))
        
        return patches, positions
    
    def generate_lrhsi_and_lms(self, images, downsample_factors, original_size=None):
        """ç”ŸæˆLRHSIå’ŒLMSæ•°æ® - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬"""
        lrhsi_data = {}
        lms_data = {}
        
        for factor in downsample_factors:
            lrhsi_data[f'LRHSI_{factor}'] = []
            lms_data[f'lms_{factor}'] = []
        
        print(f"ğŸ”„ ç”ŸæˆLRHSIå’ŒLMSæ•°æ®ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰...")
        
        for factor in downsample_factors:
            print(f"   å¤„ç†ä¸‹é‡‡æ ·å€æ•° {factor}x...")
            
            for i, image in enumerate(images):
                try:
                    # è½¬æ¢ä¸ºtensor
                    if isinstance(image, np.ndarray):
                        img_tensor = torch.from_numpy(image).float()
                    else:
                        img_tensor = image
                    
                    # ä¸‹é‡‡æ ·
                    lrhsi_tensor = anti_aliasing_downsample(img_tensor, factor, self.device)
                    
                    # ç§»åŠ¨åˆ°CPUå¹¶ä¿å­˜LRHSI
                    lrhsi = lrhsi_tensor.cpu().numpy()
                    lrhsi_data[f'LRHSI_{factor}'].append(lrhsi)
                    
                    # ç”ŸæˆLMSï¼ˆä¸Šé‡‡æ ·ï¼‰
                    target_size = original_size if original_size is not None else image.shape[-2:]
                    lrhsi_tensor = lrhsi_tensor.to(self.device)
                    lrhsi_batch = lrhsi_tensor.unsqueeze(0)
                    lms_tensor = F.interpolate(lrhsi_batch, size=target_size, 
                                             mode='bilinear', align_corners=False)
                    lms = lms_tensor.squeeze(0).cpu().numpy()
                    lms_data[f'lms_{factor}'].append(lms)
                    
                    # ç«‹å³æ¸…ç†GPUå†…å­˜
                    del img_tensor, lrhsi_tensor, lrhsi_batch, lms_tensor
                    if self.device.type == 'cuda':
                        torch.cuda.empty_cache()
                        
                except Exception as e:
                    print(f"å¤„ç†å¤±è´¥ (factor={factor}, image {i}): {e}")
                    # ä½¿ç”¨numpyåå¤‡æ–¹æ¡ˆ
                    if factor > 1:
                        lrhsi = image[:, ::factor, ::factor]
                    else:
                        lrhsi = image
                    lrhsi_data[f'LRHSI_{factor}'].append(lrhsi)
                    
                    # ç®€å•ä¸Šé‡‡æ ·
                    from scipy.ndimage import zoom
                    if original_size is not None:
                        zoom_factors = (1, original_size[0]/lrhsi.shape[-2], original_size[1]/lrhsi.shape[-1])
                        lms = zoom(lrhsi, zoom_factors, order=1)
                    else:
                        lms = lrhsi
                    lms_data[f'lms_{factor}'].append(lms)
        
        return lrhsi_data, lms_data
    
    def generate_training_set(self):
        """ç”Ÿæˆè®­ç»ƒé›†"""
        print("\n" + "="*60)
        print("1ï¸âƒ£ ç”ŸæˆPaviaUè®­ç»ƒé›†")
        print("="*60)
        
        patch_size = self.config['train_patch_size']
        stride = self.config['train_stride']
        downsample_factors = self.config['downsample_factors']
        
        print(f"è®­ç»ƒpatchå°ºå¯¸: {patch_size}x{patch_size}")
        print(f"è£å‰ªæ­¥é•¿: {stride} (é‡å è£å‰ª)")
        print(f"åŸå§‹å›¾åƒå°ºå¯¸: {self.config['original_size']}")
        
        # è£å‰ªè®­ç»ƒpatches
        print("ğŸ”¨ è£å‰ªè®­ç»ƒpatches...")
        gt_patches, positions = self.crop_patches_overlapping(self.gt_data, patch_size, stride)
        hrmsi_patches, _ = self.crop_patches_overlapping(self.hrmsi_data, patch_size, stride)
        
        print(f"æ€»è®­ç»ƒpatches: {len(gt_patches)}")
        print(f"æ¯ä¸ªpatchå°ºå¯¸: GT {gt_patches[0].shape}, HRMSI {hrmsi_patches[0].shape}")
        
        # ç”ŸæˆLRHSIå’ŒLMS
        print("ğŸ”„ ç”ŸæˆLRHSIå’ŒLMS...")
        lrhsi_data, lms_data = self.generate_lrhsi_and_lms(
            gt_patches, downsample_factors, original_size=(patch_size, patch_size)
        )
        
        # åˆ›å»ºè®­ç»ƒé›†H5æ–‡ä»¶
        train_file = os.path.join(
            self.config['output_dir'], 
            f'Botswana_train_patches_stride{stride}_size{patch_size}.h5'
        )
        
        print(f"ğŸ’¾ ä¿å­˜è®­ç»ƒé›†åˆ°: {train_file}")
        
        with h5py.File(train_file, 'w') as f:
            # ä¿å­˜GTå’ŒHRMSI
            gt_array = np.stack(gt_patches)      # (N, C, H, W)
            hrmsi_array = np.stack(hrmsi_patches)  # (N, 3, H, W)
            
            f.create_dataset('GT', data=gt_array, 
                            #  compression='gzip', 
                        #    compression_opts=self.config['compression_level']
                           )
            f.create_dataset('HRMSI', data=hrmsi_array, 
                        #      compression='gzip',
                        #    compression_opts=self.config['compression_level']
                           )
            
            # ä¿å­˜LRHSIå’ŒLMS
            for factor in downsample_factors:
                lrhsi_array = np.stack(lrhsi_data[f'LRHSI_{factor}'])
                lms_array = np.stack(lms_data[f'lms_{factor}'])
                
                f.create_dataset(f'LRHSI_{factor}', data=lrhsi_array, 
                            #    compression='gzip', compression_opts=self.config['compression_level']
                               )
                f.create_dataset(f'lms_{factor}', data=lms_array,
                            #    compression='gzip', compression_opts=self.config['compression_level']
                            )
            
            # ä¿å­˜å…ƒæ•°æ®
            f.attrs['dataset_name'] = self.dataset_name
            f.attrs['patch_size'] = patch_size
            f.attrs['stride'] = stride
            f.attrs['total_patches'] = len(gt_patches)
            f.attrs['downsample_factors'] = downsample_factors
            f.attrs['original_image_size'] = list(self.config['original_size'])
            f.attrs['num_bands'] = self.config['num_bands']
            f.attrs['data_type'] = 'train'
        
        file_size_mb = os.path.getsize(train_file) / (1024**2)
        print(f"âœ… è®­ç»ƒé›†ä¿å­˜å®Œæˆ! æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")
        
        return train_file
    
    def generate_test_set(self):
        """ç”Ÿæˆæµ‹è¯•é›†"""
        print("\n" + "="*60)
        print("2ï¸âƒ£ ç”ŸæˆPaviaCenteræµ‹è¯•é›†")
        print("="*60)
        
        crop_width = self.config['test_crop_width']
        crop_height = self.config['test_crop_height']
        patch_size = self.config['test_patch_size']
        downsample_factors = self.config['downsample_factors']
        
        print(f"æµ‹è¯•åŒºåŸŸè£å‰ª: å·¦ä¸Šè§’{crop_width}Ã—{crop_height}")
        print(f"æµ‹è¯•patchå°ºå¯¸: {patch_size}Ã—{patch_size}")
        
        # éªŒè¯å‚æ•°
        if crop_width % patch_size != 0:
            raise ValueError(f"è£å‰ªå®½åº¦{crop_width}å¿…é¡»èƒ½è¢«patchå°ºå¯¸{patch_size}æ•´é™¤")
        if crop_height % patch_size != 0:
            raise ValueError(f"è£å‰ªé«˜åº¦{crop_height}å¿…é¡»èƒ½è¢«patchå°ºå¯¸{patch_size}æ•´é™¤")
        
        patches_per_row = crop_height // patch_size
        patches_per_col = crop_width // patch_size
        total_patches = patches_per_row * patches_per_col
        print(f"æµ‹è¯•patches: {patches_per_row}Ã—{patches_per_col} = {total_patches}ä¸ª")
        
        # è£å‰ªæµ‹è¯•patches
        print("ğŸ”¨ è£å‰ªæµ‹è¯•patches...")
        gt_patches, positions = self.crop_test_patches_non_overlapping(
            self.gt_data, crop_width, crop_height, patch_size)
        hrmsi_patches, _ = self.crop_test_patches_non_overlapping(
            self.hrmsi_data, crop_width, crop_height, patch_size)
        
        print(f"å®é™…å¾—åˆ°patches: {len(gt_patches)}")
        
        # ç”ŸæˆLRHSIå’ŒLMS
        print("ğŸ”„ ç”ŸæˆLRHSIå’ŒLMS...")
        lrhsi_data, lms_data = self.generate_lrhsi_and_lms(
            gt_patches, downsample_factors, original_size=(patch_size, patch_size)
        )
        
        # åˆ›å»ºæµ‹è¯•é›†H5æ–‡ä»¶
        test_file = os.path.join(
            self.config['output_dir'], 
            f'Botswana_test_crop{crop_width}x{crop_height}_patch{patch_size}.h5'
        )
        
        print(f"ğŸ’¾ ä¿å­˜æµ‹è¯•é›†åˆ°: {test_file}")
        
        with h5py.File(test_file, 'w') as f:
            # ä¿å­˜GTå’ŒHRMSI
            gt_array = np.stack(gt_patches)      # (N, C, H, W)
            hrmsi_array = np.stack(hrmsi_patches)  # (N, 3, H, W)
            
            f.create_dataset('GT', data=gt_array)
            f.create_dataset('HRMSI', data=hrmsi_array)
            
            # ä¿å­˜LRHSIå’ŒLMS
            for factor in downsample_factors:
                lrhsi_array = np.stack(lrhsi_data[f'LRHSI_{factor}'])
                lms_array = np.stack(lms_data[f'lms_{factor}'])
                
                f.create_dataset(f'LRHSI_{factor}', data=lrhsi_array)
                f.create_dataset(f'lms_{factor}', data=lms_array)
            
            # ä¿å­˜patchä½ç½®ä¿¡æ¯
            positions_array = np.array(positions)
            f.create_dataset('patch_positions', data=positions_array)
            
            # ä¿å­˜å…ƒæ•°æ®
            f.attrs['dataset_name'] = self.dataset_name
            f.attrs['crop_width'] = crop_width
            f.attrs['crop_height'] = crop_height
            f.attrs['patch_size'] = patch_size
            f.attrs['total_patches'] = len(gt_patches)
            f.attrs['patches_per_row'] = patches_per_row
            f.attrs['patches_per_col'] = patches_per_col
            f.attrs['downsample_factors'] = downsample_factors
            f.attrs['original_image_size'] = list(self.config['original_size'])
            f.attrs['num_bands'] = self.config['num_bands']
            f.attrs['data_type'] = 'test'
    
    def verify_datasets(self, train_file, test_file):
        """éªŒè¯ç”Ÿæˆçš„æ•°æ®é›†"""
        print("\n" + "="*60)
        print("3ï¸âƒ£ éªŒè¯æ•°æ®é›†")
        print("="*60)
        
        # éªŒè¯è®­ç»ƒé›†
        print("ğŸ” éªŒè¯è®­ç»ƒé›†:")
        with h5py.File(train_file, 'r') as f:
            print(f"   æ•°æ®é›†é”®å€¼: {list(f.keys())}")
            for key in f.keys():
                if isinstance(f[key], h5py.Dataset):
                    data = f[key]
                    print(f"   {key}: {data.shape}, dtype={data.dtype}")
                    # æ£€æŸ¥æ•°æ®èŒƒå›´
                    sample_data = data[0] if len(data) > 0 else None
                    if sample_data is not None:
                        print(f"      æ•°å€¼èŒƒå›´: [{sample_data.min():.6f}, {sample_data.max():.6f}]")
            
            print(f"   å±æ€§: {dict(f.attrs)}")
        
        # éªŒè¯æµ‹è¯•é›†
        print("\nğŸ” éªŒè¯æµ‹è¯•é›†:")
        with h5py.File(test_file, 'r') as f:
            print(f"   æ•°æ®é›†é”®å€¼: {list(f.keys())}")
            for key in f.keys():
                if isinstance(f[key], h5py.Dataset):
                    data = f[key]
                    print(f"   {key}: {data.shape}, dtype={data.dtype}")
                    # æ£€æŸ¥æ•°æ®èŒƒå›´
                    sample_data = data[0] if len(data) > 0 else None
                    if sample_data is not None:
                        print(f"      æ•°å€¼èŒƒå›´: [{sample_data.min():.6f}, {sample_data.max():.6f}]")
            
            print(f"   å±æ€§: {dict(f.attrs)}")
        
        print("\nâœ… æ•°æ®é›†éªŒè¯å®Œæˆ!")
    
    def visualize_samples(self, train_file, test_file):
        """å¯è§†åŒ–æ•°æ®æ ·æœ¬"""
        print("\n" + "="*60)
        print("4ï¸âƒ£ å¯è§†åŒ–æ•°æ®æ ·æœ¬")
        print("="*60)
        
        try:
            import matplotlib.pyplot as plt
            
            # å¯è§†åŒ–è®­ç»ƒé›†æ ·æœ¬
            with h5py.File(train_file, 'r') as f:
                gt_train = f['GT'][0]        # ç¬¬ä¸€ä¸ªè®­ç»ƒpatch
                hrmsi_train = f['HRMSI'][0]  # ç¬¬ä¸€ä¸ªè®­ç»ƒpatch
                
                print(f"è®­ç»ƒæ ·æœ¬å½¢çŠ¶: GT {gt_train.shape}, HRMSI {hrmsi_train.shape}")
            
            # å¯è§†åŒ–æµ‹è¯•é›†æ ·æœ¬
            with h5py.File(test_file, 'r') as f:
                gt_test = f['GT'][0]         # ç¬¬ä¸€ä¸ªæµ‹è¯•patch
                hrmsi_test = f['HRMSI'][0]   # ç¬¬ä¸€ä¸ªæµ‹è¯•patch
                
                print(f"æµ‹è¯•æ ·æœ¬å½¢çŠ¶: GT {gt_test.shape}, HRMSI {hrmsi_test.shape}")
            
            # åˆ›å»ºå¯è§†åŒ–
            fig, axes = plt.subplots(2, 3, figsize=(15, 10))
            fig.suptitle('PaviaCenteræ•°æ®é›†æ ·æœ¬å¯è§†åŒ–', fontsize=16)
            
            # è®­ç»ƒé›†å¯è§†åŒ–
            # GTä¼ªå½©è‰² (é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æ³¢æ®µ)
            gt_train_rgb = np.stack([
                gt_train[80],   # çº¢è‰²é€šé“
                gt_train[50],   # ç»¿è‰²é€šé“  
                gt_train[20]    # è“è‰²é€šé“
            ], axis=2)
            gt_train_rgb = (gt_train_rgb - gt_train_rgb.min()) / (gt_train_rgb.max() - gt_train_rgb.min())
            
            axes[0, 0].imshow(gt_train_rgb)
            axes[0, 0].set_title('è®­ç»ƒé›†-GTä¼ªå½©è‰²')
            axes[0, 0].axis('off')
            
            # HRMSI RGB
            hrmsi_train_display = hrmsi_train.transpose(1, 2, 0)  # CHW -> HWC
            hrmsi_train_display = (hrmsi_train_display - hrmsi_train_display.min()) / (hrmsi_train_display.max() - hrmsi_train_display.min())
            
            axes[0, 1].imshow(hrmsi_train_display)
            axes[0, 1].set_title('è®­ç»ƒé›†-HRMSI RGB')
            axes[0, 1].axis('off')
            
            # ä¸‹é‡‡æ ·ç¤ºä¾‹
            if f'LRHSI_4' in f:
                with h5py.File(train_file, 'r') as f:
                    lrhsi_4 = f['LRHSI_4'][0]
                
                # ä¸Šé‡‡æ ·ç”¨äºæ˜¾ç¤º
                from scipy.ndimage import zoom
                lrhsi_4_upsampled = zoom(lrhsi_4, (1, 4, 4), order=1)
                lrhsi_4_rgb = np.stack([
                    lrhsi_4_upsampled[80],
                    lrhsi_4_upsampled[50],
                    lrhsi_4_upsampled[20]
                ], axis=2)
                lrhsi_4_rgb = (lrhsi_4_rgb - lrhsi_4_rgb.min()) / (lrhsi_4_rgb.max() - lrhsi_4_rgb.min())
                
                axes[0, 2].imshow(lrhsi_4_rgb)
                axes[0, 2].set_title('è®­ç»ƒé›†-LRHSI_4 (4å€ä¸‹é‡‡æ ·)')
                axes[0, 2].axis('off')
            
            # æµ‹è¯•é›†å¯è§†åŒ–
            gt_test_rgb = np.stack([
                gt_test[80],
                gt_test[50],
                gt_test[20]
            ], axis=2)
            gt_test_rgb = (gt_test_rgb - gt_test_rgb.min()) / (gt_test_rgb.max() - gt_test_rgb.min())
            
            axes[1, 0].imshow(gt_test_rgb)
            axes[1, 0].set_title('æµ‹è¯•é›†-GTä¼ªå½©è‰²')
            axes[1, 0].axis('off')
            
            hrmsi_test_display = hrmsi_test.transpose(1, 2, 0)
            hrmsi_test_display = (hrmsi_test_display - hrmsi_test_display.min()) / (hrmsi_test_display.max() - hrmsi_test_display.min())
            
            axes[1, 1].imshow(hrmsi_test_display)
            axes[1, 1].set_title('æµ‹è¯•é›†-HRMSI RGB')
            axes[1, 1].axis('off')
            
            if f'LRHSI_4' in f:
                with h5py.File(test_file, 'r') as f:
                    lrhsi_4_test = f['LRHSI_4'][0]
                
                lrhsi_4_test_upsampled = zoom(lrhsi_4_test, (1, 4, 4), order=1)
                lrhsi_4_test_rgb = np.stack([
                    lrhsi_4_test_upsampled[80],
                    lrhsi_4_test_upsampled[50],
                    lrhsi_4_test_upsampled[20]
                ], axis=2)
                lrhsi_4_test_rgb = (lrhsi_4_test_rgb - lrhsi_4_test_rgb.min()) / (lrhsi_4_test_rgb.max() - lrhsi_4_test_rgb.min())
                
                axes[1, 2].imshow(lrhsi_4_test_rgb)
                axes[1, 2].set_title('æµ‹è¯•é›†-LRHSI_4 (4å€ä¸‹é‡‡æ ·)')
                axes[1, 2].axis('off')
            
            plt.tight_layout()
            plt.show()
            
            print("âœ… å¯è§†åŒ–å®Œæˆ!")
            
        except ImportError:
            print("âš ï¸  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
        except Exception as e:
            print(f"âš ï¸  å¯è§†åŒ–å¤±è´¥: {e}")
    
    def run(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®é›†ç”Ÿæˆæµç¨‹"""
        print("ğŸš€ å¼€å§‹ç”ŸæˆPaviaUæ•°æ®é›†")
        print("="*80)
        
        try:
            # 1. åŠ è½½æ•°æ®
            self.load_pavia_data()
            
            # 2. ç”Ÿæˆè®­ç»ƒé›†
            train_file = self.generate_training_set()
            
            # 3. ç”Ÿæˆæµ‹è¯•é›†
            test_file = self.generate_test_set()
            
            # 4. éªŒè¯æ•°æ®é›†
            self.verify_datasets(train_file, test_file)
            
            # 5. å¯è§†åŒ–æ ·æœ¬
            self.visualize_samples(train_file, test_file)
            
            # 6. æ€»ç»“
            print("\n" + "="*80)
            print("ğŸ‰ PaviaUæ•°æ®é›†ç”Ÿæˆå®Œæˆ!")
            print("="*80)
            print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
            print(f"   è®­ç»ƒé›†: {train_file}")
            print(f"   æµ‹è¯•é›†: {test_file}")
            print()
            print("âœ… æ•°æ®é›†ç‰¹ç‚¹:")
            print(f"   â€¢ GT: {self.config['num_bands']}é€šé“é«˜å…‰è°±æ•°æ®")
            print("   â€¢ HRMSI: 3é€šé“RGBæ•°æ®")
            print("   â€¢ LRHSI_X: ä½¿ç”¨Interp23TapæŠ—æ··å ä¸‹é‡‡æ ·çš„ä½åˆ†è¾¨ç‡é«˜å…‰è°±æ•°æ®")
            print("   â€¢ lms_X: ä½¿ç”¨åŒçº¿æ€§æ’å€¼ä¸Šé‡‡æ ·å›åŸå°ºå¯¸çš„ä½åˆ†è¾¨ç‡å¤šå…‰è°±æ•°æ®")
            print(f"   â€¢ è®­ç»ƒé›†: é‡å è£åˆ‡{self.config['train_patch_size']}x{self.config['train_patch_size']} patches (æ­¥é•¿{self.config['train_stride']})")
            print(f"   â€¢ æµ‹è¯•é›†: å·¦ä¸Šè§’{self.config['test_crop_width']}x{self.config['test_crop_height']}è£åˆ‡4ä¸ª{self.config['test_patch_size']}x{self.config['test_patch_size']} patches")
            print("="*80)
            
            return train_file, test_file
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None, None

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='PaviaCenteræ•°æ®é›†ç”Ÿæˆå™¨')
    
    parser.add_argument('--pavia_file', type=str, 
                       default=PAVIA_CONFIG['pavia_file'],
                       help='PaviaCenteræ•°æ®æ–‡ä»¶è·¯å¾„')
    
    parser.add_argument('--output_dir', type=str,
                       default=PAVIA_CONFIG['output_dir'],
                       help='è¾“å‡ºç›®å½•')
    
    parser.add_argument('--train_patch_size', type=int,
                       default=PAVIA_CONFIG['train_patch_size'],
                       help='è®­ç»ƒpatchå°ºå¯¸')
    
    parser.add_argument('--train_stride', type=int,
                       default=PAVIA_CONFIG['train_stride'],
                       help='è®­ç»ƒpatchæ­¥é•¿')
    
    parser.add_argument('--test_crop_width', type=int,
                       default=PAVIA_CONFIG['test_crop_width'],
                       help='æµ‹è¯•é›†è£å‰ªå®½åº¦')
    
    parser.add_argument('--test_crop_height', type=int,
                       default=PAVIA_CONFIG['test_crop_height'],
                       help='æµ‹è¯•é›†è£å‰ªé«˜åº¦')
    
    parser.add_argument('--test_patch_size', type=int,
                       default=PAVIA_CONFIG['test_patch_size'],
                       help='æµ‹è¯•patchå°ºå¯¸')
    
    parser.add_argument('--downsample_factors', nargs='+', type=int,
                       default=PAVIA_CONFIG['downsample_factors'],
                       help='ä¸‹é‡‡æ ·å€æ•°åˆ—è¡¨')
    
    parser.add_argument('--gpu_ids', nargs='+', type=int,
                       default=[0],
                       help='ä½¿ç”¨çš„GPU IDåˆ—è¡¨')
    
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # åˆ›å»ºé…ç½®
    config = PAVIA_CONFIG.copy()
    gpu_ids = args.gpu_ids
    del args.gpu_ids
    config.update(vars(args))
    
    print("é…ç½®å‚æ•°:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    print(f"  gpu_ids: {gpu_ids}")
    print()
    
    # åˆ›å»ºç”Ÿæˆå™¨å¹¶è¿è¡Œ
    generator = PaviaCenterDatasetGenerator(config, gpu_ids=gpu_ids)
    train_file, test_file = generator.run()
    
    if train_file and test_file:
        print(f"\nâœ… PaviaCenteræ•°æ®é›†ç”ŸæˆæˆåŠŸ!")
    else:
        print(f"\nâŒ PaviaCenteræ•°æ®é›†ç”Ÿæˆå¤±è´¥!")
        sys.exit(1)

if __name__ == '__main__':
    main()