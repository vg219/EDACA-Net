#!/usr/bin/env python3
"""
æµ‹è¯•æŠ—æ··å ä¸‹é‡‡æ ·åŠŸèƒ½
"""

import torch
import numpy as np
from generate_cave_dataset import anti_aliasing_downsample
import matplotlib.pyplot as plt

def test_anti_aliasing_downsample():
    """æµ‹è¯•æŠ—æ··å ä¸‹é‡‡æ ·åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•æŠ—æ··å ä¸‹é‡‡æ ·åŠŸèƒ½...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ® - æ¨¡æ‹ŸCAVEæ•°æ®
    test_image = torch.randn(31, 128, 128).to(device)  # (C, H, W) - 31é€šé“é«˜å…‰è°±æ•°æ®
    print(f"è¾“å…¥å›¾åƒshape: {test_image.shape}")
    print(f"è¾“å…¥æ•°æ®èŒƒå›´: [{test_image.min().item():.4f}, {test_image.max().item():.4f}]")
    
    # æµ‹è¯•ä¸åŒçš„ä¸‹é‡‡æ ·å€æ•°
    factors = [2, 4, 8, 16]
    
    for factor in factors:
        print(f"\nğŸ“Š æµ‹è¯•ä¸‹é‡‡æ ·å€æ•° {factor}x...")
        
        try:
            # è¿›è¡ŒæŠ—æ··å ä¸‹é‡‡æ ·
            downsampled = anti_aliasing_downsample(test_image, factor, device)
            
            expected_h = 128 // factor
            expected_w = 128 // factor
            expected_shape = (31, expected_h, expected_w)
            
            print(f"   è¾“å…¥: {test_image.shape}")
            print(f"   è¾“å‡º: {downsampled.shape}")
            print(f"   æœŸæœ›: {expected_shape}")
            print(f"   âœ… å½¢çŠ¶æ­£ç¡®: {downsampled.shape == expected_shape}")
            
            # æ£€æŸ¥æ•°å€¼èŒƒå›´
            print(f"   è¾“å‡ºèŒƒå›´: [{downsampled.min().item():.4f}, {downsampled.max().item():.4f}]")
            
            # è®¡ç®—å‹ç¼©æ¯”
            original_pixels = np.prod(test_image.shape)
            downsampled_pixels = np.prod(downsampled.shape)
            compression_ratio = original_pixels / downsampled_pixels
            print(f"   å‹ç¼©æ¯”: {compression_ratio:.1f}x")
            
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nğŸ”„ æµ‹è¯•å®Œæ•´ä¸‹é‡‡æ ·+ä¸Šé‡‡æ ·æµç¨‹...")
    
    # æµ‹è¯•å®Œæ•´æµç¨‹ï¼šGT -> LRHSI -> LMS
    original = torch.randn(31, 128, 128).to(device)
    print(f"åŸå§‹GT: {original.shape}")
    
    factor = 4
    
    # æ­¥éª¤1: æŠ—æ··å ä¸‹é‡‡æ ·ç”ŸæˆLRHSI
    lrhsi = anti_aliasing_downsample(original, factor, device)
    print(f"LRHSI: {lrhsi.shape}")
    
    # æ­¥éª¤2: åŒçº¿æ€§æ’å€¼ä¸Šé‡‡æ ·ç”ŸæˆLMS
    lrhsi_batch = lrhsi.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
    lms = torch.nn.functional.interpolate(
        lrhsi_batch, 
        size=(128, 128), 
        mode='bilinear', 
        align_corners=False
    ).squeeze(0)
    print(f"LMS: {lms.shape}")
    
    # æ£€æŸ¥å°ºå¯¸æ¢å¤
    print(f"âœ… å°ºå¯¸æ¢å¤æ­£ç¡®: {lms.shape == original.shape}")
    
    # è®¡ç®—é‡å»ºè¯¯å·®
    mse = torch.mean((original - lms) ** 2).item()
    print(f"é‡å»ºMSE: {mse:.6f}")
    
    print("\nâœ… æŠ—æ··å ä¸‹é‡‡æ ·æµ‹è¯•å®Œæˆ!")

if __name__ == '__main__':
    test_anti_aliasing_downsample()
