# vae cfg
vae_cfg:
  pretrained_ckpt: "model/lfq_vae/ckpts/imagenet_256_L.ckpt"
  
  encoder_cfg:
    ch: 128
    in_channels: 3
    num_res_blocks: 4
    z_channels: 18
    ch_mult: [1, 1, 2, 2, 4]
    resolution: 128
    with_checkpoint: true

  decoder_cfg:
    ch: 128
    in_channels: 3
    out_ch: 3
    num_res_blocks: 4
    z_channels: 18
    ch_mult: [1, 1, 2, 2, 4]
    resolution: 128
    with_checkpoint: true
    
  lfq_cfg:
    dim: 18
    codebook_size: 262144
    # channel_first: true
    # spherical: true

dataset_cfg:
  train: 
    dataset_pattern: "/Data3/cao/ZiHanCao/exps/panformer/task_datasets/VIF-MSRS/Degraded/{0000..0001}.tar"
    extract_keys: 
      - info.json
      - encoded_instruction.npy
      - encoded_m1_degraded.npy
      - encoded_m2_degraded.npy
      - encoded_gt.npy
      - m1_clean.jpg
      - m2_clean.jpg
      # - gt.jpg
    batch_size: 32
    num_workers: 2
    n_samples_per_epoch: 3000
    shuffle_size: 100
  val:
    dataset_pattern: "/Data3/cao/ZiHanCao/exps/panformer/task_datasets/VIF-MSRS/Degraded/0002.tar"
    extract_keys:
      - info.json
      - encoded_instruction.npy
      - encoded_m1_degraded.npy
      - encoded_m2_degraded.npy
      - encoded_gt.npy
      - m1_clean.jpg
      - m2_clean.jpg
      # - gt.jpg
    batch_size: 16
    num_workers: 2
    n_samples_per_epoch: 3000
    shuffle_size: 100

maskgit_cfg:
  split_m: 2
  use_aux_loss: false
  patch_size: 16  # vae stride
  num_steps: 16
  mask_schedule_strategy: "arccos"
  guidance_scale: 0.  # no use
  sample_size: [30, 40]  # may induced from img_size
  label_smoothing: 0.1
  model_cfg:
    img_size: [480, 640]
    conditional_img_size: 256
    conditional_chans: 36
    instruction_dim: 512
    instruction_len: 77
    hidden_dim: 384
    codebook_size: 262144
    codebook_splits: 2
    depth: 8
    heads: 8
    mlp_dim: 384
    dropout: 0.05
    input_stride: 16
    use_prenorm: true
    train_frac_bits_flipped: 0.2

optimizer_cfg:
  maskgit_opt:
    name: soap_precond_palm
    lr: 2.0e-3
    weight_decay: 1.0e-6

  maskgit_sched:
    name: cos_anneal
    T_max: 40000
    eta_min: 2.0e-5
  
train_cfg:
  max_train_steps: 40000
  val_every: 500
  save_state_every: 500
  use_auxiliary_loss: false
  sanity_check_val: true
  resume_training_path: null #"/Data3/cao/ZiHanCao/exps/panformer/log_file/maskgit/dif_msrs/2024-12-05-22-52-57_maskgit_maskgit/weights/checkpoints/checkpoint_8"
  pretrained_model_path: null
  sampled_use_ema: false

ema_cfg:
  beta: 0.999
  update_after_step: 100
  update_every: 2

save_checker_cfg:
  metric_name: PSNR
  check_order: up

# logger cfg
logger_config:
  name: maskgit
  base_path: log_file/
  file_mode: w
  log_every: 5
  log_n_samples: 1
  log_val_traj: false
  log_train_img_every: 100